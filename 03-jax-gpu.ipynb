{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7f01ae3",
      "metadata": {
        "id": "a7f01ae3"
      },
      "source": [
        "# JAX on GPU\n",
        "\n",
        "In this notebook we will see how to run JAX code on GPU. We should see the difference in performance compared to CPU. This will be demonstrated on the already known Euclidean distance function.\n",
        "\n",
        "An advantage of JAX is that running on different devices, like GPU or TPU, is quite seamless. JAX can automatically run the code on the device that is available.\n",
        "\n",
        "## Caveats of GPU Computing with JAX\n",
        "\n",
        "While running JAX code on a GPU can provide significant speed-ups for large-scale numerical computations, there are several important caveats to keep in mind:\n",
        "\n",
        "- **Data Transfer Overhead**: Moving data between the CPU (host) and GPU (device) can be slow. For small datasets or frequent transfers, this overhead may outweigh the performance gains of GPU acceleration.\n",
        "\n",
        "- **JAX Array Semantics**: JAX operations are performed on `DeviceArray` objects, which reside on a specific device. Mixing NumPy arrays (on CPU) and JAX arrays (on GPU) can lead to implicit, costly data transfers. Always ensure your data is on the correct device before computation.\n",
        "\n",
        "- **GPU Memory Limitations**: GPUs typically have much less memory than CPUs. Large datasets may not fit in GPU memory, leading to out-of-memory errors.\n",
        "\n",
        "- **Non-Universal Speedup**: Not all algorithms benefit equally from GPU acceleration. Simple or memory-bound operations may not see significant improvements.\n",
        "\n",
        "- **Device Availability**: Code that runs on GPU in one environment (such as Colab) may fall back to CPU elsewhere. Always check which devices are available and handle the absence of a GPU gracefully.\n",
        "\n",
        "- **Reproducibility**: Floating-point computations on GPU may yield slightly different results compared to CPU, due to differences in hardware and parallel execution order.\n",
        "\n",
        "\n",
        "## Running in Colab\n",
        "\n",
        "Make sure to select the GPU runtime in the top right corner of the notebook.\n",
        "\n",
        "![How to change runtime to GPU in Colab](images/change-runtime-1.png)\n",
        "![How to change runtime to GPU in Colab](images/change-runtime-2.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4da720",
      "metadata": {
        "id": "df4da720"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jax\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p0aCmISh8oMT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0aCmISh8oMT",
        "outputId": "98ea08b4-2eaf-4c26-c2b9-2fe4d5f165d5"
      },
      "outputs": [],
      "source": [
        "print(f\"Jax devices: {jax.devices()}\")\n",
        "if not(any(device.platform == \"gpu\" for device in jax.devices())):\n",
        "    print(\"WARNING:No GPU found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2471889a",
      "metadata": {},
      "source": [
        "You should see something like\n",
        "```\n",
        "Jax devices: [CudaDevice(id=0)]\n",
        "```\n",
        "when running properly with a GPU device. There will be a warning if there is no GPU device.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f52870",
      "metadata": {
        "id": "e4f52870"
      },
      "source": [
        "### Performance\n",
        "\n",
        "Let's measure the performance (run time) of our algorithm. We will use the `%timeit` magic command to measure the time it takes to run the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe843aa",
      "metadata": {
        "id": "9fe843aa"
      },
      "outputs": [],
      "source": [
        "n_dataset_points: int = 10_000\n",
        "n_query_points: int = 100\n",
        "n_dim: int = 3\n",
        "k: int = 5\n",
        "\n",
        "\n",
        "def create_random_data(\n",
        "    n_points: int, n_dim: int, *, seed: int = 42\n",
        ") -> np.ndarray:\n",
        "    np.random.seed(seed)\n",
        "    return np.random.sample((n_points, n_dim)).astype(np.float32)\n",
        "\n",
        "dataset = create_random_data(n_dataset_points, n_dim, seed=420)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbef249",
      "metadata": {
        "id": "8bbef249"
      },
      "source": [
        "## JAX on GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a01f9f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a01f9f9",
        "outputId": "b30925d6-804d-4031-b085-ba8b4f1b269b"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def selu(x: jnp.ndarray, alpha: float = 1.67, lmbda: float = 1.05) -> jnp.ndarray:\n",
        "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
        "\n",
        "\n",
        "x = jnp.arange(5.0)\n",
        "print(selu(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fkVsLRy9oVD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fkVsLRy9oVD",
        "outputId": "bbfe232b-b6f3-47b2-aa86-c838c5cbbf9e"
      },
      "outputs": [],
      "source": [
        "x.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e19f55f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e19f55f",
        "outputId": "5c3297c7-9406-420f-f8a0-5471e39327ea"
      },
      "outputs": [],
      "source": [
        "key = jax.random.key(1701)\n",
        "x = jax.random.normal(key, (1_000_000,))\n",
        "\n",
        "%timeit selu(x).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4701b92a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4701b92a",
        "outputId": "e0ebc4cc-6b9e-495a-b7e9-18fd3864d20a"
      },
      "outputs": [],
      "source": [
        "selu_jit = jax.jit(selu)\n",
        "\n",
        "print(selu_jit(x)[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a569bd",
      "metadata": {
        "id": "b4a569bd"
      },
      "source": [
        "Two important things happened above:\n",
        "\n",
        "1. We instructed to Just-In-Time (JIT) compile the function when we call it.\n",
        "2. The function *was* compiled in the `print` call. It was compiled for the *concrete input type and shape*.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6c4790",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6c4790",
        "outputId": "777d5fcd-be24-4cb1-f450-ebf0024c1ab3"
      },
      "outputs": [],
      "source": [
        "%timeit selu_jit(x).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abab23d",
      "metadata": {
        "id": "2abab23d"
      },
      "source": [
        "The compiled function is significantly faster than the uncompiled one!\n",
        "\n",
        "And also much faster than the CPU version (which was around 1 ms)!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7692fc3",
      "metadata": {
        "id": "b7692fc3"
      },
      "source": [
        "### Exercise: JIT compiling Euclidean distance\n",
        "\n",
        "1. Create a JIT-compiled version of the Euclidean distance function for GPU.\n",
        "2. Compare the performance of the CPU and GPU versions.\n",
        "\n",
        "Optionally:\n",
        "\n",
        "3. Check that the GPU version yields the same result as the CPU version.\n",
        "4. Compare the scaling of the performance of CPU and GPU versions with respect to the number of query points or the number of dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8MalAO2N73FQ",
      "metadata": {
        "id": "8MalAO2N73FQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
