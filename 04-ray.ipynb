{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3497647e",
   "metadata": {},
   "source": [
    "# Parallel computation with Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54735612",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/coobas/europython-25/blob/main/04-ray.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf1e03",
   "metadata": {},
   "source": [
    "[Ray](https://docs.ray.io/en/latest/index.html) is a set of libraries that (among others) allow an easy parallelisation of Python tasks - both locally and also in clusters. This part is called **Ray Core**.\n",
    "\n",
    "Apart from this, it also provides specialised libraries for data processing (**Ray Data**), for machine learning and even reinforcement learning (**Ray Train**, **Ray Train**, ...). We will not deal with those in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8631bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in Google Collab, not needed if you install this package locally\n",
    "!pip install numpy ray[default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8faadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obligatory imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import plotly.express as px\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce591e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_COLAB = \"google.colab\" in str(get_ipython())\n",
    "\n",
    "# Download the data which are part of this repo\n",
    "if GOOGLE_COLAB:\n",
    "    import urllib\n",
    "    url = \"https://github.com/coobas/europython-25/raw/refs/heads/main/data.parquet\"\n",
    "    urllib.request.urlretrieve(url, \"data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58de68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_running(i: int) -> int:\n",
    "    \"\"\"A long running task that we will parallelise.\"\"\"\n",
    "    import time\n",
    "    time.sleep(i)\n",
    "    return i * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "long_running(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "[long_running(i) for i in range(10)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eab1e0",
   "metadata": {},
   "source": [
    "If these tasks are independent, we can run them in parallel. There are of course options in Python itself:\n",
    "\n",
    "- multiprocessing (https://docs.python.org/3.13/library/multiprocessing.html) \n",
    "- threading (with GIL-releasing code or with caution in free-threaded Python 3.13+)\n",
    "\n",
    "This does scale exactly well if there are more tasks than CPUs / GPUs on your machine...\n",
    "\n",
    "Other options:\n",
    "- [celery](https://docs.celeryq.dev/en/stable/)\n",
    "- [dask](https://docs.dask.org/en/stable/index.html)\n",
    "\n",
    "With their strengths and weaknesses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5e9c9",
   "metadata": {},
   "source": [
    "## Use ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e34b8",
   "metadata": {},
   "source": [
    "Ray always runs a server (even implicitly) and executes the task in nodes that it manages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07305b3",
   "metadata": {},
   "source": [
    "This either connects to an existing local server, or creates a new one. (In the same way, we can connect to a different one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e82ff",
   "metadata": {},
   "source": [
    "### Remote functions\n",
    "\n",
    "Any function we decorate with the `ray.remote` decorator, becomes a **task** that can be submitted to this server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55769580",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def long_running_ray(i: int) -> int:\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    return i * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dff515",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_running_ray(1)  # This will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49b322",
   "metadata": {},
   "source": [
    "Well, the error message is right. We should use `.remote` (a different one!)\n",
    "\n",
    "Better (and see that we pass arguments the same way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "long_running_ray.remote(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebce590",
   "metadata": {},
   "source": [
    "What happened? The task was submitted to the cluster. But asynchronously. We have to capture the **future** object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f784399",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = long_running_ray.remote(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcf3d0",
   "metadata": {},
   "source": [
    "...and get its value (synchronously):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d22b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "task_ids = [long_running_ray.remote(i) for i in range(10)]\n",
    "ray.get(task_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a324db",
   "metadata": {},
   "source": [
    "## Exercise: Compute k nearest neighbours in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f62167",
   "metadata": {},
   "source": [
    "We will reuse our definitions of kNN functions (slightly modified) and for random points fÃ­nd their neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b321460",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_K = 4   # How many nearest neighbors to consider\n",
    "\n",
    "def calculate_distances(query_points: np.ndarray, reference_points: np.ndarray, *, n_dim: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate mutual Euclidean distances between M query and N reference points.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    query_points: np.ndarray\n",
    "        (M, n_dim+) array of query points\n",
    "    reference_points: np.ndarray\n",
    "        (N, n_dim+) array of reference points\n",
    "    n_dim: int\n",
    "        Number of dimensions to consider (default: 3, for x, y, floor)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    distances: np.ndarray\n",
    "        (M, N) array of the distances\n",
    "    \"\"\"\n",
    "    # Expand for broadcasting\n",
    "    query_points = query_points[:, np.newaxis,:n_dim]\n",
    "    reference_points = reference_points[np.newaxis, :, :n_dim]\n",
    "    return np.sqrt(np.sum((reference_points - query_points) ** 2, axis=-1))\n",
    "\n",
    "\n",
    "def knn_search(\n",
    "    query_points: np.ndarray,\n",
    "    reference_points: np.ndarray,\n",
    "    k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Find k nearest neighbour reference point indices for N query points.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    indices: np.ndarray\n",
    "        (N, k) matrix of integral indices\n",
    "    \"\"\"\n",
    "    distances = calculate_distances(query_points, reference_points).T\n",
    "    return np.argpartition(distances, k, axis=0)[:k].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5527e",
   "metadata": {},
   "source": [
    "Let's create some points to test this on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_points(\n",
    "    n_points: int, *, n_dim: int = 3, seed: int = 42\n",
    ") -> np.ndarray:\n",
    "    # TODO: Fix floor!\n",
    "    np.random.seed(seed)\n",
    "    return np.random.sample((n_points, n_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9382f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37454012, 0.95071431, 0.73199394],\n",
       "       [0.59865848, 0.15601864, 0.15599452],\n",
       "       [0.05808361, 0.86617615, 0.60111501],\n",
       "       [0.70807258, 0.02058449, 0.96990985],\n",
       "       [0.83244264, 0.21233911, 0.18182497]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_points = create_random_points(5, seed=42)\n",
    "reference_points = create_random_points(10, seed=84)\n",
    "\n",
    "query_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9beca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82743077, 0.65400806, 0.78621956, 0.74247728, 0.88559438,\n",
       "        0.2181387 , 1.02385479, 0.93615029, 0.14672897, 0.61668925],\n",
       "       [0.59894045, 0.83501096, 0.50990624, 0.59320397, 0.63363197,\n",
       "        1.0200325 , 0.57310898, 0.94268293, 0.87078142, 0.90995193],\n",
       "       [0.61223402, 0.74973814, 0.64515347, 0.58989451, 1.0734169 ,\n",
       "        0.54579517, 1.16489686, 0.89312126, 0.30165584, 0.49965924],\n",
       "       [1.04399996, 1.28482524, 0.80396027, 0.79439734, 0.4948328 ,\n",
       "        0.88969344, 0.43420167, 0.53282295, 0.95103093, 1.36282904],\n",
       "       [0.80437579, 0.80570071, 0.70154747, 0.77224803, 0.49620442,\n",
       "        1.00473388, 0.45730809, 1.05327225, 0.91005286, 0.98827047]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_distances(query_points, reference_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7aae9",
   "metadata": {},
   "source": [
    "First, we run this without ray (for sizable arrays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54d8086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 104 ms, total: 1.98 s\n",
      "Wall time: 1.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[532, 606, 302, 371],\n",
       "       [271, 552, 872, 544],\n",
       "       [520, 125, 178, 885],\n",
       "       ...,\n",
       "       [820, 102, 966, 620],\n",
       "       [339, 990, 107, 114],\n",
       "       [847, 267,  66, 724]], shape=(32768, 4))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "query_points = create_random_points(32768, seed=42)\n",
    "reference_points = create_random_points(1000, seed=84)\n",
    "knn_search(query_points, reference_points, k=DEFAULT_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea75ba2",
   "metadata": {},
   "source": [
    "**Task**\n",
    "\n",
    "1. Change the knn_search function into a task.\n",
    "2. Submit the computation to ray and compare the results.\n",
    "3. Look at the execution times (and )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dec6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def knn_search_ray(\n",
    "    query_points: np.ndarray,\n",
    "    reference_points: np.ndarray,\n",
    "    k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Find k nearest neighbour reference point indices for N query points.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    indices: np.ndarray\n",
    "        (N, k) matrix of integral indices\n",
    "    \"\"\"\n",
    "    distances = calculate_distances(query_points, reference_points).T\n",
    "    return np.argpartition(distances, k, axis=0)[:k].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29fdb21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 4.04 ms, total: 14.6 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_id = knn_search_ray.remote(query_points, reference_points, k=DEFAULT_K)\n",
    "knn_results = ray.get(knn_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e276678",
   "metadata": {},
   "source": [
    "Is there any improvement yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e9ce7",
   "metadata": {},
   "source": [
    "## Monitoring ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18928aa6",
   "metadata": {},
   "source": [
    "Ray comes with a nice dashboard that allows you to observe running jobs. It runs in a local web server, mostly likely http://localhost:8265. This address is not accessible when running within Google Colab, and so you have to use a special trick to show a mini-window forwarded to the dashboard running in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc3e252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in google Colab. Try the local link, it should work.\n"
     ]
    }
   ],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    from google.colab import output\n",
    "    output.serve_kernel_port_as_iframe(8265)  # The port may differ!\n",
    "else:\n",
    "    print(\"Not in google Colab. Try the local link, it should work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.21 s, sys: 354 ms, total: 6.56 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8, 93,  5, 26],\n",
       "       [10, 95, 47, 51],\n",
       "       [91, 82, 22, 79],\n",
       "       ...,\n",
       "       [84, 33, 62, 32],\n",
       "       [ 8, 98, 93, 63],\n",
       "       [94, 21, 51, 16]], shape=(1000000, 4))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "query_points = create_random_points(100000, seed=42)\n",
    "reference_points = create_random_points(100, seed=84)\n",
    "knn_search(query_points, reference_points, k=DEFAULT_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589eeba",
   "metadata": {},
   "source": [
    "## Exercise: Parallelize kNN execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b08956",
   "metadata": {},
   "source": [
    "## END THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f7100",
   "metadata": {},
   "source": [
    "We have predefined reference points in an external file, modeled using an (unknown?) analytical function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405e809",
   "metadata": {},
   "source": [
    "Let's see how the whole thing looks without ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_points = create_random_points(10)\n",
    "query_points    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = compute_prices(query_points, reference_points)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_points_and_prices(query_points, prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67901582",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "1) Create a remote function variant of compute_prices (called e.g. compute_prices_ray)\n",
    "2) Run it in ray and get the result\n",
    "3) Compare the result to the previous\n",
    "4) Compare the execution time (for a larger number of points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a7388",
   "metadata": {},
   "source": [
    "## Exercise: Create a map of house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189a6d8",
   "metadata": {},
   "source": [
    "We would like to create a map of prices, i.e. sample data in a grid over the allowed area and use our kNN model to predict a price for each of those (given the floor as a parameter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf04c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = 10   # Default number of points in each dimension for the grid\n",
    "LIMIT = 10.0    # +/- Span of the grid\n",
    "\n",
    "def compute_prices(query_points, reference_points, k: int = DEFAULT_K):\n",
    "    \"\"\"\n",
    "    Find prices for N data_points.\n",
    "\n",
    "    Parameters:\n",
    "    query_points: np.ndarray\n",
    "        (N, 3) array of query points\n",
    "    reference_points: np.ndarray\n",
    "        (M, 4) array of data points with x, y, floor, and price\n",
    "    k: int\n",
    "        Number of nearest neighbors to consider\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    prices: np.ndarray\n",
    "        (N,) array of prices\n",
    "    \"\"\"\n",
    "    indices = knn_search(query_points, reference_points, k)\n",
    "    prices: np.ndarray = reference_points[indices, 3]\n",
    "    return prices.mean(axis=1)\n",
    "\n",
    "\n",
    "def combine_points_and_prices(\n",
    "    query_points: np.ndarray, prices: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare human-friendly output from numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame with columns x, y, floor, price\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"x\": query_points[:,0],\n",
    "            \"y\": query_points[:,1],\n",
    "            \"floor\": query_points[:,2],\n",
    "            \"price\": prices,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reference_points_df(path: Path = Path(\"data.parquet\")) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load reference data points from a parquet file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data_points: np.ndarray\n",
    "        (N, 4) array of data points with x, y, floor, and price columns\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_parquet(path)\n",
    "    # return df[[\"x\", \"y\", \"floor\", \"price\"]].to_numpy().astype(float)\n",
    "\n",
    "reference_points_df = load_reference_points_df()\n",
    "reference_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca859ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(n_points: int = N_POINTS) -> tuple[np.ndarray, ...]:\n",
    "    \"\"\"\n",
    "    Create a homogenous grid of points to create a map.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x: np.ndarray\n",
    "        Flattened (n_points x n_points,) array of x values\n",
    "    y: np.ndarray\n",
    "        Flattened (n_points x n_points,) array of x values\n",
    "    \"\"\"\n",
    "    # Note: Tested indirectly via `create_query_points`\n",
    "    # TODO: Add floor\n",
    "    x = np.linspace(-LIMIT, LIMIT, n_points)\n",
    "    y = np.linspace(-LIMIT, LIMIT, n_points)\n",
    "    return tuple(arr.flatten() for arr in np.meshgrid(x, y))\n",
    "\n",
    "\n",
    "def create_query_points(n_points: int = N_POINTS, floor: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a homogenous grid of points with a floor to create a map.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    query_points: np.ndarray\n",
    "        (n_points x n_points, 3) array of query points\n",
    "    \"\"\"\n",
    "    x, y = create_grid(n_points=n_points)\n",
    "    return np.vstack([x, y, np.ones(x.shape[0]) * floor]).T\n",
    "\n",
    "\n",
    "create_query_points(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9309eb",
   "metadata": {},
   "source": [
    "TODO: Create an actor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3607f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(points: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Draw points on a map.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    points: np.ndarray\n",
    "        (N, 3) array of points to draw\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"x\": points[:,0], \"y\": points[:,1]})\n",
    "    fig = px.scatter(df, x=\"x\", y=\"y\", title=\"Query points\")\n",
    "    fig.show()\n",
    "\n",
    "draw_points(create_query_points(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45cc72",
   "metadata": {},
   "source": [
    "## Exercise: Make our computation faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1511b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accelerating-scientific-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
